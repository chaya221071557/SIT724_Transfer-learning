{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbNDdbV0oqPh",
        "outputId": "41f4d6e2-a130-4731-b2f1-01ea4be31fb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.19.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: torch==2.4.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.4.0+cu121)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision) (2024.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.4.0->torchvision) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.4.0->torchvision) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torchvision --index-url https://download.pytorch.org/whl/cu118"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "import time"
      ],
      "metadata": {
        "id": "FVYuR51tpBZM"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A32kx7ATpGpf",
        "outputId": "4edaf775-2750-4e9b-9ff3-cf80ee13a370"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convolutional block with Batch Normalization and Leaky ReLU\n",
        "def conv_batch(in_channels, out_channels, kernel_size, stride, padding=1):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, bias=False),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.LeakyReLU(0.1)\n",
        "    )"
      ],
      "metadata": {
        "id": "zLk1sQbWqRGI"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dark Residual Block\n",
        "class DarkResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels):\n",
        "        super(DarkResidualBlock, self).__init__()\n",
        "        self.layer = nn.Sequential(\n",
        "            conv_batch(in_channels, in_channels // 2, kernel_size=1, stride=1, padding=0),\n",
        "            conv_batch(in_channels // 2, in_channels, kernel_size=3, stride=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.layer(x)"
      ],
      "metadata": {
        "id": "fiQ52wIlqT0G"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Making a layer with multiple residual blocks\n",
        "def make_layer(block, in_channels, num_blocks):\n",
        "    layers = []\n",
        "    for _ in range(num_blocks):\n",
        "        layers.append(block(in_channels))\n",
        "    return nn.Sequential(*layers)"
      ],
      "metadata": {
        "id": "BcLPHcCNqWfV"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the Darknet-53 Model\n",
        "class Darknet53(nn.Module):\n",
        "    def __init__(self, num_classes=26):\n",
        "        super(Darknet53, self).__init__()\n",
        "        self.conv1 = conv_batch(3, 32, kernel_size=3, stride=1)\n",
        "        self.conv2 = conv_batch(32, 64, kernel_size=3, stride=2)\n",
        "        self.residual_block1 = make_layer(DarkResidualBlock, in_channels=64, num_blocks=1)\n",
        "\n",
        "        self.conv3 = conv_batch(64, 128, kernel_size=3, stride=2)\n",
        "        self.residual_block2 = make_layer(DarkResidualBlock, in_channels=128, num_blocks=2)\n",
        "\n",
        "        self.conv4 = conv_batch(128, 256, kernel_size=3, stride=2)\n",
        "        self.residual_block3 = make_layer(DarkResidualBlock, in_channels=256, num_blocks=8)\n",
        "\n",
        "        self.conv5 = conv_batch(256, 512, kernel_size=3, stride=2)\n",
        "        self.residual_block4 = make_layer(DarkResidualBlock, in_channels=512, num_blocks=8)\n",
        "\n",
        "        self.conv6 = conv_batch(512, 1024, kernel_size=3, stride=2)\n",
        "        self.residual_block5 = make_layer(DarkResidualBlock, in_channels=1024, num_blocks=4)\n",
        "\n",
        "        self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(1024, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.residual_block1(x)\n",
        "\n",
        "        x = self.conv3(x)\n",
        "        x = self.residual_block2(x)\n",
        "\n",
        "        x = self.conv4(x)\n",
        "        x = self.residual_block3(x)\n",
        "\n",
        "        x = self.conv5(x)\n",
        "        x = self.residual_block4(x)\n",
        "\n",
        "        x = self.conv6(x)\n",
        "        x = self.residual_block5(x)\n",
        "\n",
        "        x = self.global_avg_pool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "4wkSKoEoqZa-"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# Function to load pre-trained weights using NumPy\n",
        "def load_darknet_weights(model, weights_path):\n",
        "    with open(weights_path, 'rb') as f:\n",
        "        header = f.read(16)  # Skip the first 16 bytes (metadata)\n",
        "        weights = np.fromfile(f, dtype=np.float32)  # Use NumPy to read binary weights\n",
        "\n",
        "    ptr = 0\n",
        "    for module in model.modules():\n",
        "        if isinstance(module, nn.Conv2d):\n",
        "            conv_layer = module\n",
        "\n",
        "            # Check if the layer has biases and load them if they exist\n",
        "            if conv_layer.bias is not None:\n",
        "                num_biases = conv_layer.bias.numel()\n",
        "                biases = torch.from_numpy(weights[ptr:ptr + num_biases]).view_as(conv_layer.bias.data)\n",
        "                conv_layer.bias.data.copy_(biases)\n",
        "                ptr += num_biases\n",
        "\n",
        "            # Load the weights\n",
        "            num_weights = conv_layer.weight.numel()\n",
        "            conv_weights = torch.from_numpy(weights[ptr:ptr + num_weights]).view_as(conv_layer.weight.data)\n",
        "            conv_layer.weight.data.copy_(conv_weights)\n",
        "            ptr += num_weights\n"
      ],
      "metadata": {
        "id": "GhXXzqZaqfmw"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "en0mkWskqjnc",
        "outputId": "33bad379-b93a-44ef-b7d7-64dd7a326091"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the path to your pre-trained weights\n",
        "weights_path = '/content/drive/MyDrive/darknet53.conv.74'"
      ],
      "metadata": {
        "id": "rUYotStrqrvO"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the model and load weights\n",
        "model = Darknet53(num_classes=26)\n",
        "load_darknet_weights(model, weights_path)"
      ],
      "metadata": {
        "id": "wZLT5HG4qvtI"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Optional: Freeze early layers\n",
        "for param in model.conv1.parameters():\n",
        "    param.requires_grad = False"
      ],
      "metadata": {
        "id": "hy6CVfj9q2AA"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # Resize images to 224x224\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "GciXn9Jxq4uF"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = datasets.ImageFolder(root='/content/drive/MyDrive/malevis_train_val_224x224/malevis_train_val_224x224/train', transform=transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)"
      ],
      "metadata": {
        "id": "XXnfAIa7q7RR"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_dataset = datasets.ImageFolder(root='/content/drive/MyDrive/malevis_train_val_224x224/malevis_train_val_224x224/val', transform=transform)\n",
        "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)"
      ],
      "metadata": {
        "id": "g-JIuuvKrRnq"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001)"
      ],
      "metadata": {
        "id": "1Fc6KJ99rag0"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop with time and additional metrics\n",
        "num_epochs = 25\n",
        "best_val_acc = 0.0\n",
        "best_val_loss = float('inf')\n",
        "best_precision = 0.0\n",
        "best_recall = 0.0\n",
        "best_f1 = 0.0"
      ],
      "metadata": {
        "id": "VIIesrJ_rdHx"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "txpgUXriredy"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    train_loss = running_loss / len(train_loader)\n",
        "    train_accuracy = 100 * correct / total\n",
        "\n",
        "    # Validation loop\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_labels = []\n",
        "    all_predictions = []\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            val_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_predictions.extend(predicted.cpu().numpy())\n",
        "\n",
        "    val_loss /= len(val_loader)\n",
        "    val_accuracy = 100 * correct / total\n",
        "    precision = precision_score(all_labels, all_predictions, average='macro', zero_division=1)\n",
        "    recall = recall_score(all_labels, all_predictions, average='macro',zero_division=1)\n",
        "    f1 = f1_score(all_labels, all_predictions, average='macro', zero_division=1)\n",
        "\n",
        "    # Save the best model based on validation accuracy\n",
        "    if val_accuracy > best_val_acc:\n",
        "        best_val_acc = val_accuracy\n",
        "        best_val_loss = val_loss\n",
        "        best_precision = precision\n",
        "        best_recall = recall\n",
        "        best_f1 = f1\n",
        "        torch.save(model.state_dict(), '/content/drive/MyDrive/darknet53_Malevis_model.pth')\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.2f}%, '\n",
        "          f'Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.2f}%, Precision: {precision:.4f}, '\n",
        "          f'Recall: {recall:.4f}, F1 Score: {f1:.4f}')\n",
        "\n",
        "end_time = time.time()\n",
        "elapsed_time = end_time - start_time\n",
        "minutes, seconds = divmod(elapsed_time, 60)\n",
        "\n",
        "print(f\"Training complete in {int(minutes)}m {int(seconds)}s\")\n",
        "print(f\"Best val Acc: {best_val_acc:.4f}\")\n",
        "print(f\"Best val Loss: {best_val_loss:.4f}\")\n",
        "print(f\"Best val Precision: {best_precision:.4f}\")\n",
        "print(f\"Best val Recall: {best_recall:.4f}\")\n",
        "print(f\"Best val F1 Score: {best_f1:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mA3L7fRBrgw3",
        "outputId": "5d6839e2-0a86-4464-9ff8-c6e1b343c808"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/25], Train Loss: 0.0751, Train Acc: 97.64%, Val Loss: 0.7433, Val Acc: 86.53%, Precision: 0.8711, Recall: 0.9436, F1 Score: 0.8985\n",
            "Epoch [2/25], Train Loss: 0.0668, Train Acc: 97.99%, Val Loss: 0.7756, Val Acc: 85.90%, Precision: 0.8704, Recall: 0.9254, F1 Score: 0.8898\n",
            "Epoch [3/25], Train Loss: 0.0539, Train Acc: 98.26%, Val Loss: 0.7968, Val Acc: 87.19%, Precision: 0.8856, Recall: 0.9335, F1 Score: 0.9022\n",
            "Epoch [4/25], Train Loss: 0.0508, Train Acc: 98.35%, Val Loss: 1.0780, Val Acc: 85.11%, Precision: 0.8680, Recall: 0.9439, F1 Score: 0.8948\n",
            "Epoch [5/25], Train Loss: 0.0594, Train Acc: 98.30%, Val Loss: 0.8034, Val Acc: 86.08%, Precision: 0.8696, Recall: 0.9391, F1 Score: 0.8952\n",
            "Epoch [6/25], Train Loss: 0.0624, Train Acc: 98.00%, Val Loss: 0.9731, Val Acc: 84.93%, Precision: 0.8755, Recall: 0.9376, F1 Score: 0.8951\n",
            "Epoch [7/25], Train Loss: 0.0413, Train Acc: 98.67%, Val Loss: 0.8740, Val Acc: 86.90%, Precision: 0.8761, Recall: 0.9513, F1 Score: 0.9044\n",
            "Epoch [8/25], Train Loss: 0.0368, Train Acc: 98.78%, Val Loss: 0.7971, Val Acc: 87.13%, Precision: 0.8754, Recall: 0.9447, F1 Score: 0.9024\n",
            "Epoch [9/25], Train Loss: 0.0523, Train Acc: 98.27%, Val Loss: 0.9146, Val Acc: 87.66%, Precision: 0.8901, Recall: 0.9506, F1 Score: 0.9117\n",
            "Epoch [10/25], Train Loss: 0.0368, Train Acc: 98.79%, Val Loss: 0.8321, Val Acc: 86.95%, Precision: 0.8798, Recall: 0.9448, F1 Score: 0.9036\n",
            "Epoch [11/25], Train Loss: 0.0456, Train Acc: 98.59%, Val Loss: 0.8321, Val Acc: 87.36%, Precision: 0.8797, Recall: 0.9444, F1 Score: 0.9045\n",
            "Epoch [12/25], Train Loss: 0.0241, Train Acc: 99.23%, Val Loss: 0.9004, Val Acc: 87.17%, Precision: 0.8850, Recall: 0.9460, F1 Score: 0.9065\n",
            "Epoch [13/25], Train Loss: 0.0401, Train Acc: 98.75%, Val Loss: 0.9713, Val Acc: 85.51%, Precision: 0.8750, Recall: 0.9418, F1 Score: 0.8968\n",
            "Epoch [14/25], Train Loss: 0.0372, Train Acc: 98.91%, Val Loss: 0.7319, Val Acc: 87.64%, Precision: 0.8824, Recall: 0.9470, F1 Score: 0.9069\n",
            "Epoch [15/25], Train Loss: 0.0322, Train Acc: 98.97%, Val Loss: 0.8366, Val Acc: 87.29%, Precision: 0.8803, Recall: 0.9502, F1 Score: 0.9067\n",
            "Epoch [16/25], Train Loss: 0.0321, Train Acc: 99.08%, Val Loss: 0.9822, Val Acc: 86.62%, Precision: 0.8810, Recall: 0.9470, F1 Score: 0.9039\n",
            "Epoch [17/25], Train Loss: 0.0420, Train Acc: 98.65%, Val Loss: 1.1435, Val Acc: 85.28%, Precision: 0.8713, Recall: 0.9413, F1 Score: 0.8952\n",
            "Epoch [18/25], Train Loss: 0.0254, Train Acc: 99.15%, Val Loss: 1.0051, Val Acc: 86.92%, Precision: 0.8821, Recall: 0.9481, F1 Score: 0.9064\n",
            "Epoch [19/25], Train Loss: 0.0204, Train Acc: 99.33%, Val Loss: 1.1411, Val Acc: 86.51%, Precision: 0.8784, Recall: 0.9522, F1 Score: 0.9052\n",
            "Epoch [20/25], Train Loss: 0.0181, Train Acc: 99.43%, Val Loss: 1.0209, Val Acc: 87.68%, Precision: 0.8869, Recall: 0.9488, F1 Score: 0.9097\n",
            "Epoch [21/25], Train Loss: 0.0430, Train Acc: 98.60%, Val Loss: 0.8188, Val Acc: 87.23%, Precision: 0.8803, Recall: 0.9471, F1 Score: 0.9048\n",
            "Epoch [22/25], Train Loss: 0.0205, Train Acc: 99.45%, Val Loss: 0.9077, Val Acc: 87.85%, Precision: 0.8944, Recall: 0.9491, F1 Score: 0.9124\n",
            "Epoch [23/25], Train Loss: 0.0251, Train Acc: 99.14%, Val Loss: 1.3633, Val Acc: 86.55%, Precision: 0.8780, Recall: 0.9493, F1 Score: 0.9041\n",
            "Epoch [24/25], Train Loss: 0.0228, Train Acc: 99.35%, Val Loss: 0.8933, Val Acc: 87.13%, Precision: 0.8814, Recall: 0.9494, F1 Score: 0.9063\n",
            "Epoch [25/25], Train Loss: 0.0263, Train Acc: 99.11%, Val Loss: 1.2015, Val Acc: 87.03%, Precision: 0.8808, Recall: 0.9457, F1 Score: 0.9044\n",
            "Training complete in 36m 8s\n",
            "Best val Acc: 87.8505\n",
            "Best val Loss: 0.9077\n",
            "Best val Precision: 0.8944\n",
            "Best val Recall: 0.9491\n",
            "Best val F1 Score: 0.9124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(os.listdir('/content/drive/MyDrive/'))  # Replace with your directory\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_QSmUKX3W7in",
        "outputId": "f05b1fef-a43e-4181-d51d-7dbf4eba5845"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Colab Notebooks', 'Blended', 'darknet53.conv.74', 'data_224_g', 'malevis_train_val_224x224', 'darknet53_full_model.pth', 'darknet53_Blended_model.pth', 'darknet53_Malevis_model.pth']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "# Prediction function\n",
        "def predict_image(image_path, model, class_names):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "    # Image transformations\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),  # Resize image to 224x224\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    # Load image and apply transformations\n",
        "    image = Image.open(image_path).convert('RGB')  # Convert to RGB to ensure 3 channels\n",
        "    image = transform(image).unsqueeze(0)  # Add batch dimension\n",
        "\n",
        "    # Move image to device\n",
        "    image = image.to(device)\n",
        "\n",
        "    # Make prediction\n",
        "    with torch.no_grad():\n",
        "        outputs = model(image)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "\n",
        "    # Get the class name\n",
        "    predicted_class = class_names[preds.item()]\n",
        "    return predicted_class\n",
        "\n",
        "# Load the saved model\n",
        "model = Darknet53(num_classes=26)  # Ensure num_classes matches your model\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/darknet53_Malevis_model.pth', weights_only=False))  # Load the best saved model\n",
        "model = model.to(device)\n",
        "\n",
        "# Example usage\n",
        "class_names = train_dataset.classes  # Get class names from the training dataset\n",
        "image_path = '/content/drive/MyDrive/malevis_train_val_224x224/malevis_train_val_224x224/val/Snarasite/b54292debb22cad5bfa4862a3f3ce8107d6950eeresized_image.png'  # Replace with the path to your image\n",
        "predicted_class = predict_image(image_path, model, class_names)\n",
        "print(f\"Predicted class: {predicted_class}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5LUMpZK8XF0f",
        "outputId": "0ef798da-84ae-4801-b4b4-89638d9b5c14"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class: Snarasite\n"
          ]
        }
      ]
    }
  ]
}